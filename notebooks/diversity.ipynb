{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"7\"\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (196523630.py, line 18)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[22], line 18\u001b[0;36m\u001b[0m\n\u001b[0;31m    outputs = ..\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "from rlvsil.diversity import DEFAULT_CONFIGS, calculate_diversity_metrics\n",
    "\n",
    "diversity_metrics = [\"ead_averaged_distinct_ngrams\",\"nli_sample_from_sim\",\"sent_bert_from_sim\"]\n",
    "no_overall_input = True\n",
    "sample_overall = True\n",
    "no_per_input = False\n",
    "\n",
    "outputs = ...\n",
    "\n",
    "diversity_metrics_config = DEFAULT_CONFIGS.copy()\n",
    "if diversity_metrics != \"all\":\n",
    "    diversity_metrics_config = {\n",
    "        k: v for k, v in diversity_metrics_config.items() if k in diversity_metrics\n",
    "    }\n",
    "print(diversity_metrics_config)\n",
    "\n",
    "run_results = calculate_diversity_metrics(\n",
    "    outputs, diversity_metrics_config, no_per_input, no_overall_input, sample_overall\n",
    ")\n",
    "pprint(run_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CosineSimilarity2Diversity: 0.667\n",
      "DistinctNgrams: 0.750\n",
      "AveragedCosineSimilarity: 0.737\n",
      "AveragedDistinctNgrams: 0.593\n"
     ]
    }
   ],
   "source": [
    "# resp_set = [\"bla bla\", \"daj wiersz\", \"zaszczekaj glosno i dlugo\"]\n",
    "\n",
    "from rlvsil.diversity.diversity_metrics import CosineSimilarity2Diversity, AveragedCosineSimilarity, AveragedDistinctNgrams, DistinctNgrams\n",
    "\n",
    "\n",
    "def print_metric(metric, resp_set):\n",
    "    print(\"{0}: {1:0.3f}\".format(type(metric).__name__, metric(resp_set)))\n",
    "\n",
    "# TEST\n",
    "resp_set = [\"i am going\", \"i am going\", \"lets go i i\"]\n",
    "config = {\"n\": 3}\n",
    "print_metric(CosineSimilarity2Diversity(config), resp_set)\n",
    "print_metric(DistinctNgrams(config), resp_set)\n",
    "\n",
    "avg_config = {\"n_min\": 1, \"n_max\": 5}\n",
    "print_metric(AveragedCosineSimilarity(avg_config), resp_set)\n",
    "print_metric(AveragedDistinctNgrams(avg_config), resp_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rlvsil.diversity import DEFAULT_CONFIGS, calculate_diversity_metrics\n",
    "\n",
    "\n",
    "# metrics from paper: ead_averaged_distinct_ngrams, nli_sample_from_sim, sent_bert_from_sim\n",
    "\n",
    "\n",
    "outputss = [\n",
    "    [\n",
    "        \"I like to eat apples.\",\n",
    "        \"I like to eat bananas.\",\n",
    "        \"I like to eat oranges.\",\n",
    "    ],\n",
    "    [\n",
    "        \"I love to eat apples.\",\n",
    "        \"I love to eat bananas.\",\n",
    "        \"I love to eat oranges.\",\n",
    "    ],\n",
    "    [\n",
    "        \"I love muching on apples.\",\n",
    "        \"I love muching on bananas.\",\n",
    "        \"I love muching on oranges.\",\n",
    "    ],\n",
    "]\n",
    "config = DEFAULT_CONFIGS.copy()\n",
    "del config[\"openai_from_sim\"]\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "pprint(config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/djaniak/mambaforge/envs/rlhf-gen-div/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at roberta-large-mnli were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at roberta-large-mnli were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating per-input diversities\n",
      "Average per-input diversities:\n",
      "{'mean_per_input_averaged_distinct_ngrams': 0.6377777777777778, 'mean_per_input_ead_averaged_distinct_ngrams': 0.6378211785884894, 'mean_per_input_cosine_similarity_2d_diversity': 0.3333333333333333, 'mean_per_input_sent_bert_from_sim': 0.40668171644210815, 'mean_per_input_nli_from_sim': -0.978046695391337, 'mean_per_input_nli_sample_from_sim': 0.9884730033079783}\n",
      "Std per-input diversities:\n",
      "{'std_per_input_averaged_distinct_ngrams': 0.0, 'std_per_input_ead_averaged_distinct_ngrams': 0.0, 'std_per_input_cosine_similarity_2d_diversity': 5.551115123125783e-17, 'std_per_input_sent_bert_from_sim': 0.0597790032252103, 'std_per_input_nli_from_sim': 0.00554125843101213, 'std_per_input_nli_sample_from_sim': 0.061663088363215636}\n",
      "calculating overall diversities\n",
      "Average overall diversities:\n",
      "{'overall_averaged_distinct_ngrams': 0.5388888888888889, 'overall_ead_averaged_distinct_ngrams': 0.538994964957481, 'overall_cosine_similarity_2d_diversity': 0.8055555555555556, 'overall_sent_bert_from_sim': 0.3989078998565674, 'overall_nli_from_sim': -0.0003935595353443677, 'overall_nli_sample_from_sim': 0.8940553428067102}\n",
      "calculating overall single-input diversities\n",
      "Average overall single-input diversities:\n",
      "{'overall_single_output_averaged_distinct_ngrams': 0.8344444444444445, 'overall_single_output_ead_averaged_distinct_ngrams': 0.8345037971855376, 'overall_single_output_cosine_similarity_2d_diversity': 0.888888888888889, 'overall_single_output_sent_bert_from_sim': 0.09744042158126831, 'overall_single_output_nli_from_sim': 2.911579628785451, 'overall_single_output_nli_sample_from_sim': 0.9225597453117371}\n"
     ]
    }
   ],
   "source": [
    "results = calculate_diversity_metrics(outputss, metric_configs=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean_per_input_averaged_distinct_ngrams': 0.6377777777777778,\n",
      " 'mean_per_input_cosine_similarity_2d_diversity': 0.3333333333333333,\n",
      " 'mean_per_input_ead_averaged_distinct_ngrams': 0.6378211785884894,\n",
      " 'mean_per_input_nli_from_sim': -0.978046695391337,\n",
      " 'mean_per_input_nli_sample_from_sim': 0.8935476626290214,\n",
      " 'mean_per_input_sent_bert_from_sim': 0.40668171644210815,\n",
      " 'overall_averaged_distinct_ngrams': 0.5388888888888889,\n",
      " 'overall_cosine_similarity_2d_diversity': 0.8055555555555556,\n",
      " 'overall_ead_averaged_distinct_ngrams': 0.538994964957481,\n",
      " 'overall_nli_from_sim': -0.0003935595353443677,\n",
      " 'overall_nli_sample_from_sim': 0.9086641861332787,\n",
      " 'overall_sent_bert_from_sim': 0.3989078998565674,\n",
      " 'overall_single_output_averaged_distinct_ngrams': 0.8344444444444445,\n",
      " 'overall_single_output_cosine_similarity_2d_diversity': 0.888888888888889,\n",
      " 'overall_single_output_ead_averaged_distinct_ngrams': 0.8345037971855376,\n",
      " 'overall_single_output_nli_from_sim': 2.911579628785451,\n",
      " 'overall_single_output_nli_sample_from_sim': 0.9028316164016723,\n",
      " 'overall_single_output_sent_bert_from_sim': 0.09744042158126831,\n",
      " 'std_per_input_averaged_distinct_ngrams': 0.0,\n",
      " 'std_per_input_cosine_similarity_2d_diversity': 5.551115123125783e-17,\n",
      " 'std_per_input_ead_averaged_distinct_ngrams': 0.0,\n",
      " 'std_per_input_nli_from_sim': 0.00554125843101213,\n",
      " 'std_per_input_nli_sample_from_sim': 0.024729607744886473,\n",
      " 'std_per_input_sent_bert_from_sim': 0.0597790032252103}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers==4.36.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/djaniak/mambaforge/envs/rlhf-gen-div/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5c80cc875754ed0a66a6ea00798d736",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "\n",
    "model_name = \"speakleash/Bielik-7B-v0.1\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.bfloat16).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = \"speakleash/Bielik-Instruct-7B-v0.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output 1:\n",
      "Pewnego razu w lesie...\n",
      "2015-05-23 11:50:27\n",
      "Po wejściu do Ojcowskiego Parku Narodowego pierwsze co r\n",
      "\n",
      "Output 2:\n",
      "Pewnego razu w lesie nieopodal Headingstone znaleziono ciało młodego, około dwudziestopięcioletniego chłopaka. Dwó\n",
      "\n",
      "Output 3:\n",
      "Pewnego razu w lesie Entów, mieliśmy okazję poznać jednego z nich, Drzewca. W opowieści tej były wspomniane Entowe żony\n",
      "\n",
      "Output 4:\n",
      "Pewnego razu w lesie... Siedzący nad jeziorem leśnik obserwuje łódkę geologów zbierających próbki na dnie, korzystają\n",
      "\n",
      "Output 5:\n",
      "Pewnego razu w lesie zgasło Słońce i robiło się coraz zimniej. Leśne zwierzęta zaczęły się coraz bardziej denerwować\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "prompt = \"Pewnego razu w lesie\"\n",
    "N = 5\n",
    "temperature = 1.0  \n",
    "\n",
    "input_ids = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "\n",
    "outputs = []\n",
    "for _ in range(N):\n",
    "    output = model.generate(input_ids.to(device),\n",
    "                            pad_token_id=tokenizer.eos_token_id,\n",
    "                            do_sample=True, \n",
    "                            max_length=50, \n",
    "                            temperature=temperature, \n",
    "                            top_k=0,\n",
    "                            top_p=1\n",
    "                            )\n",
    "    \n",
    "    generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    outputs.append(generated_text)\n",
    "\n",
    "# Print the outputs\n",
    "for i, output in enumerate(outputs):\n",
    "    print(f\"Output {i+1}:\\n{output}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "info",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
