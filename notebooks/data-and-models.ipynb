{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets\n",
    "\n",
    "| SFT | summarisation | https://huggingface.co/datasets/UCL-DARK/openai-tldr-filtered |\n",
    "| --- | --- | --- |\n",
    "| RM | summarisation | https://huggingface.co/datasets/UCL-DARK/openai-tldr-summarisation-preferences |\n",
    "| PPO | summarisation | https://huggingface.co/datasets/UCL-DARK/openai-tldr-filtered |\n",
    "| ID test set | summarisation | TL;DR test set from https://huggingface.co/datasets/UCL-DARK/openai-tldr-filtered |\n",
    "| OOD test set  | summarisation | CNN/DailyMail https://huggingface.co/datasets/abisee/cnn_dailymail |\n",
    "| SFT | instruction following | sft split from https://huggingface.co/datasets/tatsu-lab/alpaca_farm  |\n",
    "|  RM | instruction following | preference split from https://huggingface.co/datasets/tatsu-lab/alpaca_farm |\n",
    "| PPO | instruction following | unlabeled split from https://huggingface.co/datasets/tatsu-lab/alpaca_farm |\n",
    "| ID test set | instruction following | ID test set is a new test set generated in the same way as the training set was for AlpacaFarm, using the AlpacaFarm variant of Self-Instruct: https://huggingface.co/datasets/UCL-DARK/alpaca-farm-id-test  |\n",
    "| OOD test set | instruction following | the AlpacaEval evaluation test set proposed in the original paper: https://huggingface.co/datasets/tatsu-lab/alpaca_eval  |\n",
    "| OOD test set | instruction following | For an additional OOD test set, we generate a set of Sequential Instructions using an adjusted Self-Instruct protocol: https://huggingface.co/datasets/UCL-DARK/sequential-instructions  |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/djaniak/mambaforge/envs/info/lib/python3.10/site-packages/datasets/load.py:1486: FutureWarning: The repository for tatsu-lab/alpaca_eval contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/tatsu-lab/alpaca_eval\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "\n",
    "instuctions_datasets = {\n",
    "    \"ID_alpaca_farm_test\": load_dataset(\"UCL-DARK/alpaca-farm-id-test\")[\"train\"],\n",
    "    \"OOD_sequential_instructions\": load_dataset(\"UCL-DARK/sequential-instructions\")[\"train\"],\n",
    "    \"OOD_alpaca_eval\": load_dataset(\"tatsu-lab/alpaca_eval\")[\"eval\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ID_alpaca_farm_test': Dataset({\n",
       "     features: ['dataset', 'instruction', 'output', 'generator'],\n",
       "     num_rows: 1033\n",
       " }),\n",
       " 'OOD_sequential_instructions': Dataset({\n",
       "     features: ['dataset', 'instruction', 'output', 'generator'],\n",
       "     num_rows: 533\n",
       " }),\n",
       " 'OOD_alpaca_eval': Dataset({\n",
       "     features: ['instruction', 'output', 'generator', 'dataset'],\n",
       "     num_rows: 805\n",
       " })}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instuctions_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ultra_datasets = {\n",
    "    \"ultra_feedback60k\": load_dataset(\"openbmb/UltraFeedback\"),\n",
    "    \"ultra_chat200k\": load_dataset(\"HuggingFaceH4/ultrachat_200k\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ultra_feedback60k': DatasetDict({\n",
       "     train: Dataset({\n",
       "         features: ['source', 'instruction', 'models', 'completions', 'correct_answers', 'incorrect_answers'],\n",
       "         num_rows: 63967\n",
       "     })\n",
       " }),\n",
       " 'ultra_chat200k': DatasetDict({\n",
       "     train_sft: Dataset({\n",
       "         features: ['prompt', 'prompt_id', 'messages'],\n",
       "         num_rows: 207865\n",
       "     })\n",
       "     test_sft: Dataset({\n",
       "         features: ['prompt', 'prompt_id', 'messages'],\n",
       "         num_rows: 23110\n",
       "     })\n",
       "     train_gen: Dataset({\n",
       "         features: ['prompt', 'prompt_id', 'messages'],\n",
       "         num_rows: 256032\n",
       "     })\n",
       "     test_gen: Dataset({\n",
       "         features: ['prompt', 'prompt_id', 'messages'],\n",
       "         num_rows: 28304\n",
       "     })\n",
       " })}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ultra_datasets"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "info",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
